{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Chris\n",
    "\n",
    "The goal is to create a chatbot, given a variable length input sequence to output a variable length output that sounds like Chris is writing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (0.5.1)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "!pip install emoji\n",
    "import emoji\n",
    "\n",
    "# keras with tensorflow backend\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.layers import Flatten, RepeatVector, TimeDistributed, CuDNNLSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical, np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "% matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "mpl.rcParams['figure.dpi']= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from Txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "txt_files = glob.glob(os.path.join(data_folder, '*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_name(name):\n",
    "#     corr = re.sub('[^A-Za-z0-9öüäéè ]+', '', name)\n",
    "#     if (corr[-1] == ' '):\n",
    "#         corr = corr[:-1]\n",
    "#     return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_df_from_txt_file(file_name):\n",
    "#     f = open(file_name)\n",
    "#     file_name = os.path.split(file_name)[1]\n",
    "    \n",
    "#     date = []\n",
    "#     time = []\n",
    "#     sender = []\n",
    "#     reciever = []\n",
    "#     message = []\n",
    "\n",
    "#     partner_name = file_name[18:-4] + \": \"\n",
    "#     chris_name = 'Christoph Bernkopf: '\n",
    "\n",
    "#     i = 0\n",
    "#     for line in f:\n",
    "#         i += 1\n",
    "#         if(len(line) < 2 or \"Nachrichten in diesem Chat sowie Anrufe\" in line):\n",
    "#     #         print(\"skip line\")\n",
    "#             continue\n",
    "#         if(line[15:18] == \" - \" and line[2] == \".\" and line[5] == \".\"):\n",
    "#             date.append(line[:8])\n",
    "#             time.append(line[10:15])\n",
    "#             if (chris_name in line[18:]):\n",
    "#                 sender.append(clean_name(chris_name[:-2]))\n",
    "#                 reciever.append(clean_name(partner_name[:-2]))\n",
    "#             else:\n",
    "#                 reciever.append(clean_name(chris_name[:-2]))\n",
    "#                 sender.append(clean_name(partner_name[:-2]))\n",
    "#             message.append(line[18:].replace(partner_name, '').replace(chris_name, ''))\n",
    "\n",
    "#     df = pd.DataFrame(date, columns=['date'])\n",
    "#     df['time'] = time\n",
    "#     df['sender'] = sender\n",
    "#     df['reciever'] = reciever\n",
    "#     df['message'] = message\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     del df\n",
    "# except:\n",
    "#     None\n",
    "\n",
    "# for file_name in txt_files:\n",
    "#     print(file_name)\n",
    "#     curr_df = get_df_from_txt_file(file_name)\n",
    "#     if ('df' in locals()):\n",
    "#         df = pd.concat([df, curr_df])\n",
    "#     else:\n",
    "#         df = curr_df\n",
    "#     df = df.reset_index(drop=True)\n",
    "#     print(curr_df.shape, df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Messages into Inputs and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_list = ['<Medien ausgeschlossen>', '\\n', 'Martin TPH CERN <3: ', 'Christoph Gerhardus :): ', 'Megan :): ', 'Standort: ']\n",
    "\n",
    "# for item in remove_list:\n",
    "#     df['message'] = df['message'].apply(lambda x: x.replace(item, ''))\n",
    "\n",
    "# # df['message'] = df['message'][df['message'].astype('str').str[:10] != \"Standort: \"]\n",
    "\n",
    "# # get rid of links\n",
    "# df['message'] = df['message'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "# # get rid of nan messages\n",
    "# df['message'] = df['message'].apply(lambda x : x if type(x) == str else \"\")\n",
    "\n",
    "# df = df[df['message'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def func(x):\n",
    "#     if (type(x) != str):\n",
    "#         print(x)\n",
    "        \n",
    "# df['message'].apply(lambda x: func(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def char_is_emoji(character):\n",
    "#     return character in emoji.UNICODE_EMOJI\n",
    "\n",
    "# def char_is_spe_char(character):\n",
    "#     return character in \"?!.\"\n",
    "\n",
    "# def text_has_emoji(text):\n",
    "#     for character in text:\n",
    "#         if character in emoji.UNICODE_EMOJI:\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "# def text_has_spe_char(text):\n",
    "#     for character in text:\n",
    "#         if character in \"?!.\":\n",
    "#             return True\n",
    "#     return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def space_emoijis(x):\n",
    "#     if (text_has_emoji(x) or text_has_spe_char(x)):\n",
    "#         result = ''\n",
    "#         if (len(x) == 1):\n",
    "#             return result\n",
    "#         for ch in x:\n",
    "#             if (char_is_emoji(ch)):\n",
    "#                 result = result + ' ' + ch\n",
    "#             elif (char_is_spe_char(ch)):\n",
    "#                 result = result + ' ' + ch\n",
    "#             else:\n",
    "#                 result = result + ch\n",
    "#         return result\n",
    "#     else:\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df['message'] = df['message'].apply(lambda x: space_emoijis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['sender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_message(i,j):\n",
    "#     msg = df.iloc[i:j,df.columns.get_loc('message')].values\n",
    "#     assert msg.shape[0] > 0\n",
    "\n",
    "#     if (msg.shape[0] > 1):\n",
    "#         inpu = msg[0]\n",
    "#         for m in msg[1:]:\n",
    "#             inpu = \"%s \\n %s\" % (inpu, m)\n",
    "#     else:\n",
    "#         inpu = msg[0]\n",
    "        \n",
    "#     return inpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_agg_message(i, name):\n",
    "#     col = df.columns.get_loc('reciever')\n",
    "    \n",
    "#     for j in range(1000):\n",
    "#         j = i + j\n",
    "#         if (name == df.iloc[j,col]):\n",
    "#             break    \n",
    "#     inpu = get_message(i,j)\n",
    "        \n",
    "#     for k in range(1000):\n",
    "#         k = j + k\n",
    "#         if (name != df.iloc[k,col]):\n",
    "#             break\n",
    "#     target = get_message(j,k)\n",
    "    \n",
    "#     return inpu, target, k-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = []\n",
    "# tar = []\n",
    "# sen = []\n",
    "# rec = []\n",
    "\n",
    "# i = 0\n",
    "# while i<(len(df)-10):\n",
    "# # while i<15:\n",
    "#     # get input & target\n",
    "#     col = df.columns.get_loc('sender')\n",
    "#     name = df.iloc[i,col]\n",
    "#     next_names = df.iloc[i+1:i+10,col].values\n",
    "#     if (name != \"Christoph Bernkopf\" and name in next_names):\n",
    "#         inpu, target, i = get_agg_message(i, name)    \n",
    "#         inp.append(inpu)\n",
    "#         tar.append(target)\n",
    "#         sen.append(name)\n",
    "#         rec.append(\"Christoph Bernkopf\")\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfn = pd.DataFrame(inp, columns=['input'])\n",
    "# dfn['target'] = tar\n",
    "# dfn['sender'] = sen\n",
    "# dfn['reciever'] = rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A little bit of filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dfn = dfn[dfn['input'].astype('str').str.len()>20]\n",
    "# dfn.head()\n",
    "# dfn.to_pickle(os.path.join(data_folder, \"preprocessed_data.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = pd.read_pickle(os.path.join(data_folder, \"preprocessed_data.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfn['input'].values\n",
    "y = dfn['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "tok = Tokenizer(num_words=max_words, filters='\"#$%&()*+,-./;<=>@[\\]^_`{|}~ ')\n",
    "tok.fit_on_texts(np.concatenate([X,y]))\n",
    "\n",
    "def tok_and_pad(arr):\n",
    "    sequences = tok.texts_to_sequences(arr)\n",
    "    return sequences\n",
    "\n",
    "X = tok_and_pad(X)\n",
    "y = tok_and_pad(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((388,), (113,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = np.array([len(elem) for elem in X])\n",
    "y_lengths = np.array([len(elem) for elem in y])\n",
    "lengths[lengths>50].shape, y_lengths[y_lengths>50].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val = 25\n",
    "sns.distplot(lengths[lengths<50],kde=False,\n",
    "             axlabel=\"Port\",label=\"Benign\",color=\"R\", norm_hist=True);\n",
    "plt.legend();\n",
    "plt.title(\"Name\",fontsize=20);\n",
    "# plt.savefig(os.path.join(\"EDA_plots\", col, name))\n",
    "plt.show()\n",
    "# plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: classify input by sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = pd.read_pickle(os.path.join(data_folder, \"preprocessed_data.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alexander Götz', 'Christoph Gerhardus',\n",
       "       'Daniel TPH Rideclub Marik', 'Daniel TPH Rugby', 'Fabian Fürst',\n",
       "       'Lukas', 'Mama', 'Martin TPH CERN 3', 'Max Frèremano',\n",
       "       'Max Maxi Frühschütz Fabian', 'Megan', 'Milica Modeschule'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dfn['input'].values\n",
    "y = dfn['sender'].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "# y = y.reshape(-1,1)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Passt dann bin ich um 0800 dort \\n Fleißig fleißig ! \\n Wo genau ?',\n",
       "       'reco die live läuft ? was ist das ? hahaha',\n",
       "       'Wird aber 21:15 werden \\n 23', 'ee nice \\n schaut cool aus',\n",
       "       'ich seh halt nicht wie es aussieht \\n wie gesagt'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "max_len = 200\n",
    "tok = Tokenizer(num_words=max_words, filters='\"#$%&()*+,-./;<=>@[\\]^_`{|}~ ')\n",
    "tok.fit_on_texts(X_train)\n",
    "\n",
    "def tok_and_pad(arr):\n",
    "    sequences = tok.texts_to_sequences(arr)\n",
    "    return sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "\n",
    "train_sequences_matrix = tok_and_pad(X_train)\n",
    "val_sequences_matrix = tok_and_pad(X_val)\n",
    "test_sequences_matrix = tok_and_pad(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n</td>\n",
       "      <td>13378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ich</td>\n",
       "      <td>4013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>?</td>\n",
       "      <td>3085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>du</td>\n",
       "      <td>2266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>und</td>\n",
       "      <td>1937.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word    count\n",
       "7     \\n  13378.0\n",
       "3    ich   4013.0\n",
       "12     ?   3085.0\n",
       "119   du   2266.0\n",
       "149  und   1937.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tok.word_counts\n",
    "names = ['word','count']\n",
    "formats = ['object','f8']\n",
    "dtype = dict(names = names, formats=formats)\n",
    "arr = np.array(list(tok.word_counts.items()), dtype=dtype)\n",
    "arr = pd.DataFrame(arr)\n",
    "arr.sort_values(by=['count'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3329938900203666"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_classifier.fit(train_sequences_matrix, y_train)\n",
    "acc_dummy_classifier = dummy_classifier.score(val_sequences_matrix, y_val)\n",
    "acc_dummy_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fabian Fürst'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, indices = np.unique(y_val, return_inverse=True)\n",
    "most_freq_y_val = u[np.argmax(np.bincount(indices))]\n",
    "le.inverse_transform(most_freq_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2525458248472505"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(train_sequences_matrix, y_train)\n",
    "tree_score = tree.score(val_sequences_matrix, y_val)\n",
    "tree_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/kredy10/simple-lstm-for-text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_val = np_utils.to_categorical(y_val)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, key_dim=None, **kwargs):\n",
    "        self.key_dim = key_dim\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "         # Weights initializer function\n",
    "        w_initializer = keras.initializers.glorot_uniform()\n",
    "\n",
    "        # Biases initializer function\n",
    "        b_initializer = keras.initializers.Zeros()\n",
    "        \n",
    "        #Matrix to extract the keys\n",
    "        self.key_extract = self.add_weight(name='feature_extract', \n",
    "                                      shape=(int(input_shape[2]),int(self.key_dim)),\n",
    "                                      initializer=w_initializer,\n",
    "                                      trainable=True)\n",
    "        #Key Bias\n",
    "        self.key_bias = self.add_weight(name='feaure_bias', \n",
    "                                      shape=(int(1),int(self.key_dim)),\n",
    "                                      initializer=b_initializer,\n",
    "                                      trainable=True)\n",
    "        \n",
    "        #The Query representing the class\n",
    "        self.Query = self.add_weight(name='Query', \n",
    "                                      shape=(int(self.key_dim),int(1)),\n",
    "                                      initializer=w_initializer,\n",
    "                                      trainable=True)\n",
    "\n",
    "        super(Attention, self).build(input_shape) \n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        #Extract the Keys\n",
    "        keys=tf.tensordot(x,self.key_extract,axes=[2,0])+self.key_bias\n",
    "        \n",
    "        #Calculate the similarity between keys and the Query\n",
    "        similar_logits=tf.tensordot(keys,self.Query,axes=[2,0])\n",
    "        \n",
    "        #Normalize it to be between 0 and 1 and sum to 1\n",
    "        attention_weights = tf.nn.sigmoid(similar_logits)\n",
    "        \n",
    "        #Use these Weights to aggregate\n",
    "        weighted_input = tf.matmul(x, attention_weights, transpose_a=True)\n",
    "\n",
    "        return [weighted_input, attention_weights]\n",
    "\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [(input_shape[0],input_shape[2],int(1)), (input_shape[0],input_shape[1],1)]\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(Attention, self).get_config()\n",
    "        base_config['key_dim'] = self.key_dim\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(64, return_sequences=True)(layer)\n",
    "    layer, attention_weights = Attention(256)(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(len(le.classes_),name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 50)           1000000   \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 200, 64)           29696     \n",
      "_________________________________________________________________\n",
      "attention_1 (Attention)      [(None, 64, 1), (None, 20 16896     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 12)                3084      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 1,066,316\n",
      "Trainable params: 1,066,316\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', # RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8831 samples, validate on 982 samples\n",
      "Epoch 1/10\n",
      "8831/8831 [==============================] - 5s 536us/step - loss: 2.1107 - acc: 0.3364 - val_loss: 2.0238 - val_acc: 0.3330\n",
      "Epoch 2/10\n",
      "8831/8831 [==============================] - 3s 302us/step - loss: 1.9899 - acc: 0.3473 - val_loss: 1.8966 - val_acc: 0.3350\n",
      "Epoch 3/10\n",
      "8831/8831 [==============================] - 3s 304us/step - loss: 1.7216 - acc: 0.3928 - val_loss: 1.6455 - val_acc: 0.4236\n",
      "Epoch 4/10\n",
      "8831/8831 [==============================] - 3s 303us/step - loss: 1.2878 - acc: 0.5777 - val_loss: 1.4313 - val_acc: 0.5682\n",
      "Epoch 5/10\n",
      "8831/8831 [==============================] - 3s 301us/step - loss: 0.8639 - acc: 0.7338 - val_loss: 1.3990 - val_acc: 0.5906\n",
      "Epoch 6/10\n",
      "8831/8831 [==============================] - 3s 303us/step - loss: 0.5862 - acc: 0.8221 - val_loss: 1.4720 - val_acc: 0.6008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1942e0a898>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sequences_matrix,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(val_sequences_matrix, y_val),\n",
    "          callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1091/1091 [==============================] - 0s 334us/step\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(test_sequences_matrix,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.623281\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy %f\" % accr[1])\n",
    "# not bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain an output sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = pd.read_pickle(os.path.join(data_folder, \"preprocessed_data.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfn['input'].values\n",
    "y = dfn['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10904,), (21808,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, np.concatenate([X,y]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokeization starts at 1 (0 is not a token key)\n",
    "- Start == -1\n",
    "- End == -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "max_len = 50\n",
    "tok = Tokenizer(num_words=max_words, filters='\"#$%&()*+,-./;<=>@[\\]^_`{|}~ ')\n",
    "tok.fit_on_texts(np.concatenate([X,y]))\n",
    "\n",
    "def tok_and_pad(arr, flag):\n",
    "    if (flag == \"input\"):\n",
    "        sequences = tok.texts_to_sequences(arr)\n",
    "        return sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "    else:\n",
    "        sequences = tok.texts_to_sequences(arr)\n",
    "        for i in range(len(sequences)):\n",
    "            sequences[i] = np.insert(sequences[i][:48], 0, -1, axis=0)\n",
    "            sequences[i] = np.append(sequences[i], [-2])\n",
    "        return sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "\n",
    "X_train = tok_and_pad(X_train, \"input\")\n",
    "X_test = tok_and_pad(X_test, \"input\")\n",
    "X_val = tok_and_pad(X_val, \"input\")\n",
    "y_train = tok_and_pad(y_train, \"target\")\n",
    "y_test = tok_and_pad(y_test, \"target\")\n",
    "y_val = tok_and_pad(y_val, \"target\")\n",
    "\n",
    "# reverse_word_map = dict(map(reversed, tok.word_index.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, inputs, targets, batch_size=32, n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        \n",
    "        X = self.inputs[list_IDs_temp]\n",
    "        y = np_utils.to_categorical(self.targets[list_IDs_temp], num_classes=max_words)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'n_classes': 6,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Datasets\n",
    "train_keys = np.arange(y_train.shape[0])\n",
    "val_keys = np.arange(y_val.shape[0])\n",
    "test_keys = np.arange(y_test.shape[0])\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(train_keys, X_train, y_train, **params)\n",
    "validation_generator = DataGenerator(val_keys, X_val, y_val, **params)\n",
    "test_generator = DataGenerator(test_keys, X_test, y_test, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Shot Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = max_words\n",
    "src_txt_length = max_len\n",
    "sum_txt_length = max_len\n",
    "\n",
    "def RNN():\n",
    "    # encoder input model\n",
    "    inputs = Input(shape=(src_txt_length,))\n",
    "    encoder1 = Embedding(vocab_size, 128)(inputs)\n",
    "    encoder2 = CuDNNLSTM(128, return_sequences=False)(encoder1)\n",
    "    encoder3 = RepeatVector(sum_txt_length)(encoder2)\n",
    "    \n",
    "    # decoder output model\n",
    "    decoder1 = LSTM(128, return_sequences=True)(encoder3)\n",
    "    outputs = TimeDistributed(Dense(vocab_size, activation='softmax'))(decoder1)\n",
    "\n",
    "    # tie it together\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    print(\"inputs.shape  \", inputs.shape)\n",
    "    print(\"encoder1.shape\", encoder1.shape)\n",
    "    print(\"encoder2.shape\", encoder2.shape)\n",
    "    print(\"encoder2.shape\", encoder2.shape)\n",
    "    print(\"decoder1.shape\", decoder1.shape)\n",
    "    print(\"outputs.shape \", outputs.shape)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape   (?, 50)\n",
      "encoder1.shape (?, 50, 128)\n",
      "encoder2.shape (?, 50, 128)\n",
      "encoder2.shape (?, 50, 128)\n",
      "decoder1.shape (?, ?, 128)\n",
      "outputs.shape  (?, 50, 20000)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 50, 128)           2560000   \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 50, 128)           132096    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 128)           131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 50, 20000)         2580000   \n",
      "=================================================================\n",
      "Total params: 5,403,680\n",
      "Trainable params: 5,403,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', # RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "137/137 [==============================] - 59s 431ms/step - loss: 2.0747 - acc: 0.7498 - val_loss: 2.0352 - val_acc: 0.7564\n",
      "Epoch 2/10\n",
      "137/137 [==============================] - 58s 425ms/step - loss: 2.0698 - acc: 0.7496 - val_loss: 2.0474 - val_acc: 0.7554\n",
      "Epoch 3/10\n",
      "137/137 [==============================] - 59s 430ms/step - loss: 2.0685 - acc: 0.7496 - val_loss: 2.0413 - val_acc: 0.7565\n",
      "Epoch 4/10\n",
      "137/137 [==============================] - 59s 429ms/step - loss: 2.0700 - acc: 0.7493 - val_loss: 2.0415 - val_acc: 0.7564\n",
      "Epoch 5/10\n",
      "137/137 [==============================] - 58s 427ms/step - loss: 2.0664 - acc: 0.7497 - val_loss: 2.0407 - val_acc: 0.7564\n",
      "Epoch 6/10\n",
      "137/137 [==============================] - 59s 427ms/step - loss: 2.0649 - acc: 0.7498 - val_loss: 2.0440 - val_acc: 0.7559\n",
      "Epoch 7/10\n",
      "137/137 [==============================] - 58s 424ms/step - loss: 2.0660 - acc: 0.7496 - val_loss: 2.0314 - val_acc: 0.7573\n",
      "Epoch 8/10\n",
      "137/137 [==============================] - 59s 427ms/step - loss: 2.0641 - acc: 0.7498 - val_loss: 2.0454 - val_acc: 0.7556\n",
      "Epoch 9/10\n",
      "137/137 [==============================] - 58s 427ms/step - loss: 2.0654 - acc: 0.7496 - val_loss: 2.0375 - val_acc: 0.7566\n",
      "Epoch 10/10\n",
      "137/137 [==============================] - 59s 430ms/step - loss: 2.0671 - acc: 0.7494 - val_loss: 2.0419 - val_acc: 0.7562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f19203b4978>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=training_generator,\n",
    "          validation_data=validation_generator,\n",
    "          epochs=10,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred[batch, word_idx, onehot_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32294685, 0.02451575, 0.0075489 , 0.00642102, 0.00479144],\n",
       "       [0.32294685, 0.02451575, 0.0075489 , 0.00642102, 0.00479144],\n",
       "       [0.32294685, 0.02451575, 0.0075489 , 0.00642102, 0.00479144],\n",
       "       [0.32294685, 0.02451575, 0.0075489 , 0.00642102, 0.00479144],\n",
       "       [0.32294685, 0.02451575, 0.0075489 , 0.00642102, 0.00479144]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0:5,0,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74875426, 0.02603604, 0.00554971, 0.0044905 , 0.00305811],\n",
       "       [0.74875426, 0.02603604, 0.00554971, 0.0044905 , 0.00305811],\n",
       "       [0.74875426, 0.02603604, 0.00554971, 0.0044905 , 0.00305811],\n",
       "       [0.74875426, 0.02603604, 0.00554971, 0.0044905 , 0.00305811],\n",
       "       [0.74875426, 0.02603604, 0.00554971, 0.0044905 , 0.00305811]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0:5,45,0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get token key with np.argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.4875426e-01, 2.6036039e-02, 5.5497107e-03, ..., 1.5508141e-06,\n",
       "       1.9479748e-02, 1.9385826e-02], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[0][10], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,   -1,   93,  143,  106,   13,    5,   23,  246, 2523,\n",
       "         11,    1,   46,   12, 4560,   -2], dtype=int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_train[10], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
