{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Chris\n",
    "\n",
    "The goal is to create a chatbot, given a variable length input sequence to output a variable length output that sounds like Chris is writing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /Users/christoph/anaconda3/lib/python3.6/site-packages (0.5.1)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "!pip install emoji\n",
    "import emoji\n",
    "\n",
    "# keras with tensorflow backend\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Flatten # , CuDNNLSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical, np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from Txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "txt_files = glob.glob(os.path.join(data_folder, '*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    corr = re.sub('[^A-Za-z0-9Ã¶Ã¼Ã¤Ã©Ã¨ ]+', '', name)\n",
    "    if (corr[-1] == ' '):\n",
    "        corr = corr[:-1]\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_txt_file(file_name):\n",
    "    f = open(file_name)\n",
    "    file_name = os.path.split(file_name)[1]\n",
    "    \n",
    "    date = []\n",
    "    time = []\n",
    "    sender = []\n",
    "    reciever = []\n",
    "    message = []\n",
    "\n",
    "    partner_name = file_name[18:-4] + \": \"\n",
    "    chris_name = 'Christoph Bernkopf: '\n",
    "\n",
    "    for line in f:\n",
    "        if(len(line) < 2 or \"Nachrichten in diesem Chat sowie Anrufe\" in line):\n",
    "    #         print(\"skip line\")\n",
    "            continue\n",
    "        if(line[15:18] == \" - \" and line[2] == \".\" and line[5] == \".\"):\n",
    "            date.append(line[:8])\n",
    "            time.append(line[10:15])\n",
    "            if (chris_name in line[18:]):\n",
    "                sender.append(clean_name(chris_name[:-2]))\n",
    "                reciever.append(clean_name(partner_name[:-2]))\n",
    "            else:\n",
    "                reciever.append(clean_name(chris_name[:-2]))\n",
    "                sender.append(clean_name(partner_name[:-2]))\n",
    "            message.append(line[18:].replace(partner_name, '').replace(chris_name, ''))\n",
    "\n",
    "    df = pd.DataFrame(date, columns=['date'])\n",
    "    df['time'] = time\n",
    "    df['sender'] = sender\n",
    "    df['reciever'] = reciever\n",
    "    df['message'] = message\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/WhatsApp Chat mit Lukas â›µ.txt\n",
      "(1958, 5) (1958, 5)\n",
      "data/WhatsApp Chat mit Max FrÃ¨remano ðŸ˜ðŸ’šðŸ.txt\n",
      "(11562, 5) (13520, 5)\n",
      "data/WhatsApp Chat mit Megan ).txt\n",
      "(8546, 5) (22066, 5)\n",
      "data/WhatsApp Chat mit Daniel TPH Rugby.txt\n",
      "(2659, 5) (24725, 5)\n",
      "data/WhatsApp Chat mit Mama ðŸ˜·ðŸ‘€.txt\n",
      "(880, 5) (25605, 5)\n",
      "data/WhatsApp Chat mit Daniel TPH Rideclub Marik.txt\n",
      "(328, 5) (25933, 5)\n",
      "data/WhatsApp Chat mit Milica Modeschule.txt\n",
      "(1941, 5) (27874, 5)\n",
      "data/WhatsApp Chat mit Max Maxi FrÃ¼hschÃ¼tz Fabian.txt\n",
      "(2807, 5) (30681, 5)\n",
      "data/WhatsApp Chat mit Christoph Gerhardus ).txt\n",
      "(3823, 5) (34504, 5)\n",
      "data/WhatsApp Chat mit Alexander GÃ¶tz.txt\n",
      "(1186, 5) (35690, 5)\n",
      "data/WhatsApp Chat mit Fabian FÃ¼rst.txt\n",
      "(25829, 5) (61519, 5)\n",
      "data/WhatsApp Chat mit Martin TPH CERN 3.txt\n",
      "(5326, 5) (66845, 5)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del df\n",
    "except:\n",
    "    None\n",
    "\n",
    "for file_name in txt_files:\n",
    "    print(file_name)\n",
    "    curr_df = get_df_from_txt_file(file_name)\n",
    "    if ('df' in locals()):\n",
    "        df = pd.concat([df, curr_df])\n",
    "    else:\n",
    "        df = curr_df\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(curr_df.shape, df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Messages into Inputs and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = ['<Medien ausgeschlossen>', '\\n', 'Martin TPH CERN <3: ', 'Christoph Gerhardus :): ', 'Megan :): ', 'Standort: ']\n",
    "\n",
    "for item in remove_list:\n",
    "    df['message'] = df['message'].apply(lambda x: x.replace(item, ''))\n",
    "\n",
    "# df['message'] = df['message'][df['message'].astype('str').str[:10] != \"Standort: \"]\n",
    "\n",
    "# get rid of links\n",
    "df['message'] = df['message'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "# get rid of nan messages\n",
    "df['message'] = df['message'].apply(lambda x : x if type(x) == str else \"\")\n",
    "\n",
    "df = df[df['message'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    if (type(x) != str):\n",
    "        print(x)\n",
    "        \n",
    "df['message'].apply(lambda x: func(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_is_emoji(character):\n",
    "    return character in emoji.UNICODE_EMOJI\n",
    "\n",
    "def char_is_spe_char(character):\n",
    "    return character in \"?!.\"\n",
    "\n",
    "def text_has_emoji(text):\n",
    "    for character in text:\n",
    "        if character in emoji.UNICODE_EMOJI:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def text_has_spe_char(text):\n",
    "    for character in text:\n",
    "        if character in \"?!.\":\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_emoijis(x):\n",
    "    if (text_has_emoji(x) or text_has_spe_char(x)):\n",
    "        result = ''\n",
    "        if (len(x) == 1):\n",
    "            return result\n",
    "        for ch in x:\n",
    "            if (char_is_emoji(ch)):\n",
    "                result = result + ' ' + ch\n",
    "            elif (char_is_spe_char(ch)):\n",
    "                result = result + ' ' + ch\n",
    "            else:\n",
    "                result = result + ch\n",
    "        return result\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['message'] = df['message'].apply(lambda x: space_emoijis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lukas', 'Christoph Bernkopf', 'Max FrÃ¨remano', 'Megan',\n",
       "       'Daniel TPH Rugby', 'Mama', 'Daniel TPH Rideclub Marik',\n",
       "       'Milica Modeschule', 'Max Maxi FrÃ¼hschÃ¼tz Fabian',\n",
       "       'Christoph Gerhardus', 'Alexander GÃ¶tz', 'Fabian FÃ¼rst',\n",
       "       'Martin TPH CERN 3'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_message(i,j):\n",
    "    msg = df.iloc[i:j,df.columns.get_loc('message')].values\n",
    "    assert msg.shape[0] > 0\n",
    "\n",
    "    if (msg.shape[0] > 1):\n",
    "        inpu = msg[0]\n",
    "        for m in msg[1:]:\n",
    "            inpu = \"%s \\n %s\" % (inpu, m)\n",
    "    else:\n",
    "        inpu = msg[0]\n",
    "        \n",
    "    return inpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agg_message(i, name):\n",
    "    col = df.columns.get_loc('reciever')\n",
    "    \n",
    "    for j in range(1000):\n",
    "        j = i + j\n",
    "        if (name == df.iloc[j,col]):\n",
    "            break    \n",
    "    inpu = get_message(i,j)\n",
    "        \n",
    "    for k in range(1000):\n",
    "        k = j + k\n",
    "        if (name != df.iloc[k,col]):\n",
    "            break\n",
    "    target = get_message(j,k)\n",
    "    \n",
    "    return inpu, target, k-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = []\n",
    "tar = []\n",
    "sen = []\n",
    "rec = []\n",
    "\n",
    "i = 0\n",
    "while i<(len(df)-10):\n",
    "# while i<15:\n",
    "    # get input & target\n",
    "    col = df.columns.get_loc('sender')\n",
    "    name = df.iloc[i,col]\n",
    "    next_names = df.iloc[i+1:i+10,col].values\n",
    "    if (name != \"Christoph Bernkopf\" and name in next_names):\n",
    "        inpu, target, i = get_agg_message(i, name)    \n",
    "        inp.append(inpu)\n",
    "        tar.append(target)\n",
    "        sen.append(name)\n",
    "        rec.append(\"Christoph Bernkopf\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = pd.DataFrame(inp, columns=['input'])\n",
    "dfn['target'] = tar\n",
    "dfn['sender'] = sen\n",
    "dfn['reciever'] = rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A little bit of filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfn = dfn[dfn['input'].astype('str').str.len()>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>sender</th>\n",
       "      <th>reciever</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Was gibts ? Kann heut leider nicht</td>\n",
       "      <td>Was machst heute ?</td>\n",
       "      <td>Lukas</td>\n",
       "      <td>Christoph Bernkopf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lernen \\n Und bin bei einer maturafeier</td>\n",
       "      <td>Leinwand \\n Leiwand \\n Wann hast die letzte Pr...</td>\n",
       "      <td>Lukas</td>\n",
       "      <td>Christoph Bernkopf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dreier ! \\n Und 10ects ^^</td>\n",
       "      <td>Leiwand ! \\n Wurde das so schnell kontrolliert ?</td>\n",
       "      <td>Lukas</td>\n",
       "      <td>Christoph Bernkopf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kann ich mir vorstellen \\n Alles gut gelaufen ?</td>\n",
       "      <td>Ja bis jetzt schon einigermaÃŸen \\n Aber ich ha...</td>\n",
       "      <td>Lukas</td>\n",
       "      <td>Christoph Bernkopf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr . Roberts \\n ^^ \\n , Gfr \\n Lol</td>\n",
       "      <td>Dr . Broberts \\n , Gfr  ðŸ˜‚ ðŸ˜‚ ðŸ˜‚ ðŸ˜‚ ðŸ˜‚</td>\n",
       "      <td>Lukas</td>\n",
       "      <td>Christoph Bernkopf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input  \\\n",
       "0               Was gibts ? Kann heut leider nicht   \n",
       "1          Lernen \\n Und bin bei einer maturafeier   \n",
       "3                        Dreier ! \\n Und 10ects ^^   \n",
       "5  Kann ich mir vorstellen \\n Alles gut gelaufen ?   \n",
       "9               Dr . Roberts \\n ^^ \\n , Gfr \\n Lol   \n",
       "\n",
       "                                              target sender  \\\n",
       "0                                 Was machst heute ?  Lukas   \n",
       "1  Leinwand \\n Leiwand \\n Wann hast die letzte Pr...  Lukas   \n",
       "3   Leiwand ! \\n Wurde das so schnell kontrolliert ?  Lukas   \n",
       "5  Ja bis jetzt schon einigermaÃŸen \\n Aber ich ha...  Lukas   \n",
       "9                  Dr . Broberts \\n , Gfr  ðŸ˜‚ ðŸ˜‚ ðŸ˜‚ ðŸ˜‚ ðŸ˜‚  Lukas   \n",
       "\n",
       "             reciever  \n",
       "0  Christoph Bernkopf  \n",
       "1  Christoph Bernkopf  \n",
       "3  Christoph Bernkopf  \n",
       "5  Christoph Bernkopf  \n",
       "9  Christoph Bernkopf  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn.to_pickle(os.path.join(data_folder, \"preprocessed_data.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: classify input by sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alexander GÃ¶tz', 'Christoph Gerhardus',\n",
       "       'Daniel TPH Rideclub Marik', 'Daniel TPH Rugby', 'Fabian FÃ¼rst',\n",
       "       'Lukas', 'Mama', 'Martin TPH CERN 3', 'Max FrÃ¨remano',\n",
       "       'Max Maxi FrÃ¼hschÃ¼tz Fabian', 'Megan', 'Milica Modeschule'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dfn['input'].values\n",
    "y = dfn['sender'].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "# y = y.reshape(-1,1)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WÃ¼rd jz auch ur viel Zeit kosten',\n",
       "       'Doch \\n Hatte Handy auf Flugmodus',\n",
       "       'Alright \\n Das war ernst gemeint, du bist auf einem Keks gesessen und hatâ€™s KrÃ¼mel am arsch !',\n",
       "       'Kein Problem ! ! \\n Sie sagen sie sind dir nicht bÃ¶se weil sie happy sind dass du so brav auf mich aufpasst  ðŸ˜˜ \\n Btw meine GroÃŸmutter aus Frankreich hat dich im Juli ein Wochenende nach Frankreich eingeladen, you should come wenn du zeit hast:) \\n (Ihr Fleischhauer ist skydiver und wir wurden schon angekÃ¼ndigt haha)',\n",
       "       'Verpasster Sprachanruf'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "max_len = 200\n",
    "tok = Tokenizer(num_words=max_words, filters='\"#$%&()*+,-./;<=>@[\\]^_`{|}~ ')\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "train_sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "\n",
    "sequences = tok.texts_to_sequences(X_val)\n",
    "val_sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3615071283095723"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_classifier.fit(train_sequences_matrix, y_train)\n",
    "acc_dummy_classifier = dummy_classifier.score(val_sequences_matrix, y_val)\n",
    "acc_dummy_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christoph/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fabian FÃ¼rst'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, indices = np.unique(y_val, return_inverse=True)\n",
    "most_freq_y_val = u[np.argmax(np.bincount(indices))]\n",
    "le.inverse_transform(most_freq_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2556008146639511"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(train_sequences_matrix, y_train)\n",
    "tree_score = tree.score(val_sequences_matrix, y_val)\n",
    "tree_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/kredy10/simple-lstm-for-text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_val = np_utils.to_categorical(y_val)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, key_dim=None, **kwargs):\n",
    "        self.key_dim = key_dim\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "         # Weights initializer function\n",
    "        w_initializer = keras.initializers.glorot_uniform()\n",
    "\n",
    "        # Biases initializer function\n",
    "        b_initializer = keras.initializers.Zeros()\n",
    "        \n",
    "        #Matrix to extract the keys\n",
    "        self.key_extract = self.add_weight(name='feature_extract', \n",
    "                                      shape=(int(input_shape[2]),int(self.key_dim)),\n",
    "                                      initializer=w_initializer,\n",
    "                                      trainable=True)\n",
    "        #Key Bias\n",
    "        self.key_bias = self.add_weight(name='feaure_bias', \n",
    "                                      shape=(int(1),int(self.key_dim)),\n",
    "                                      initializer=b_initializer,\n",
    "                                      trainable=True)\n",
    "        \n",
    "        #The Query representing the class\n",
    "        self.Query = self.add_weight(name='Query', \n",
    "                                      shape=(int(self.key_dim),int(1)),\n",
    "                                      initializer=w_initializer,\n",
    "                                      trainable=True)\n",
    "\n",
    "        super(Attention, self).build(input_shape) \n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        #Extract the Keys\n",
    "        keys=tf.tensordot(x,self.key_extract,axes=[2,0])+self.key_bias\n",
    "        \n",
    "        #Calculate the similarity between keys and the Query\n",
    "        similar_logits=tf.tensordot(keys,self.Query,axes=[2,0])\n",
    "        \n",
    "        #Normalize it to be between 0 and 1 and sum to 1\n",
    "        attention_weights = tf.nn.sigmoid(similar_logits)\n",
    "        \n",
    "        #Use these Weights to aggregate\n",
    "        weighted_input = tf.matmul(x, attention_weights, transpose_a=True)\n",
    "\n",
    "        return [weighted_input, attention_weights]\n",
    "\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [(input_shape[0],input_shape[2],int(1)), (input_shape[0],input_shape[1],1)]\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(Attention, self).get_config()\n",
    "        base_config['key_dim'] = self.key_dim\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "#     layer = CuDNNLSTM(64, return_sequences=True)(layer)\n",
    "    layer = LSTM(64, return_sequences=True)(layer)\n",
    "    layer, attention_weights = Attention(256)(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(len(le.classes_),name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 200, 50)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 200, 64)           29440     \n",
      "_________________________________________________________________\n",
      "attention_3 (Attention)      [(None, 64, 1), (None, 20 16896     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 12)                3084      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 1,066,060\n",
      "Trainable params: 1,066,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', # RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8831 samples, validate on 982 samples\n",
      "Epoch 1/10\n",
      "8831/8831 [==============================] - 21s 2ms/step - loss: 2.1209 - acc: 0.3241 - val_loss: 1.9812 - val_acc: 0.3615\n",
      "Epoch 2/10\n",
      "8831/8831 [==============================] - 19s 2ms/step - loss: 2.0031 - acc: 0.3463 - val_loss: 1.8748 - val_acc: 0.3615\n",
      "Epoch 3/10\n",
      "8831/8831 [==============================] - 21s 2ms/step - loss: 1.7090 - acc: 0.4049 - val_loss: 1.5690 - val_acc: 0.4868\n",
      "Epoch 4/10\n",
      "8831/8831 [==============================] - 27s 3ms/step - loss: 1.2670 - acc: 0.5902 - val_loss: 1.4042 - val_acc: 0.5866\n",
      "Epoch 5/10\n",
      "8831/8831 [==============================] - 25s 3ms/step - loss: 0.8781 - acc: 0.7206 - val_loss: 1.3435 - val_acc: 0.6120\n",
      "Epoch 6/10\n",
      "8831/8831 [==============================] - 22s 3ms/step - loss: 0.5965 - acc: 0.8175 - val_loss: 1.4926 - val_acc: 0.6324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2c5402e8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sequences_matrix,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_data=(val_sequences_matrix, y_val),\n",
    "          callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1091/1091 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(test_sequences_matrix,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.611366\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy %f\" % accr[1])\n",
    "# not bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
